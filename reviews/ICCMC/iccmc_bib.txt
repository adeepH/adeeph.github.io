@INPROCEEDINGS{9418446,  author={Hande, Adeep and Puranik, Karthik and Priyadharshini, Ruba and Thavareesan, Sajeetha and Chakravarthi, Bharathi Raja},  booktitle={2021 5th International Conference on Computing Methodologies and Communication (ICCMC)},   title={Evaluating Pretrained Transformer-based Models for COVID-19 Fake News Detection},   year={2021},  volume={},  number={},  pages={766-772},  abstract={The expeditious growth of technology with social media as a platform for communication has led to a proliferous increase in the spread of misinformation and fake news. The ongoing COVID-19 widespread has pushed us to review posts on various social media platforms to stop people from being subjected to false and perilous posts. Detecting fake news in social media has been the need of an hour. The proposed research work has approached it with various Transformer and recurrent models with several contextual word embedding models. Furthermore, the effectiveness of the proposed model is evaluated by using a different loss function instead of the conventional loss function, Binary cross Entropy. The fake news detection is considered as a sequence classification task, one of the downstream tasks of natural language processing. It has been observed that using domain-specific language models along with custom loss function has achieved the highest weighted average F1-score.},  keywords={},  doi={10.1109/ICCMC51019.2021.9418446},  ISSN={},  month={April},}