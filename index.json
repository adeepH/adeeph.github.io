[{"authors":null,"categories":null,"content":"I am a Research Associate at Laboratory for Computational Social Systems (LCS2), IIIT-Delhi, working on misinformation detection and verification under the supervision of Prof. Tanmoy Chakraborty in collaboration with Accenture Labs. I am interested in Deep Learning and its applications in Natural Language Processing and related interdisciplinary fields.\nI completed my undergraduation in Software Engineering from Delhi Technological University supervised by Prof. Ruchika Malhotra. In the four years of my undergraduation, I applied AI in the fields of Computational Neuroscience (with Prof. Tapan Gandhi, IIT Delhi), surveillance, privacy protection, software engineering and most recently for fighting misinformation related to COVID-19. I\u0026rsquo;m deeply fascinated by the power and utility it possesses and aim to bring a change in this world with the help of theoretical and applied Machine Learning, Deep Learning, and Natural Language Processing with a strong inclination towards researching the mathematics behind them.\nI am also passionate about communities and aim to create equal opportunities in STEM by promoting diversity and inclusion. I am a Lead at Women Who Code Delhi and founded the community MLNerdie x Delhi to bridge the gap between academia and industry in machine learning.\n","date":1603956532,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1603956532,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://shreyagupta08.github.io/author/shreya-gupta/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shreya-gupta/","section":"authors","summary":"I am a Research Associate at Laboratory for Computational Social Systems (LCS2), IIIT-Delhi, working on misinformation detection and verification under the supervision of Prof. Tanmoy Chakraborty in collaboration with Accenture Labs.","tags":null,"title":"Shreya Gupta","type":"authors"},{"authors":["Shreya Gupta"],"categories":[],"content":"Working on my last project on claim detection in online text I hypothesized using syntactic information in addition to semantic information given the proven and claimed importance of sentence structure in formation of a claim. While generating POS and dependency trees I realised a gap we have so blissfully been ignorant of.\nBefore the advent of Deep Learning major NLP tasks used syntactic parsers. They produced parsings like POS tags, Dependency trees and Constituency trees. With the rise of Deep Learning more tasks could be magically solved. These black boxes preceeded by embedding methods like BERT need meaningful inputs like sentences. Now we have a tree that contains a lot of useful syntactic information that is inherently important for any machine to learn natural language AND we have this revolutionary black box (DL) BUT we do not have anything that can connect the two.\n This makes me question if dependency and constituency trees are the best way to represent syntactic information for the coming age deep learning algorithms?\n Is there any other way to encapsulate the subject-verb-object agreement, and the grammar and sentence formation notion in a way that is meaningful for BERT/XLNet and consequently CNNs/LSTMs.\n Maybe what we are looking for is a new form of syntactic parsing that is built on the past ideas and can also capture the sentence structure of gen-z lingo that exists online in a machine interpretable way?\n Maybe there already exist some parsing, for english or a low-resource language, that has accidentally solved this problem and is hence applicable for this chain of thought?\nIf this makes you think or if there is something I\u0026rsquo;ve missed, pick my brain at shreyag [at] iiitd [dot] ac [dot] in\n","date":1603956532,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603956532,"objectID":"51ef31dd28f04ea82db856091c00cbce","permalink":"https://shreyagupta08.github.io/post/new-parser/","publishdate":"2020-10-29T12:58:52+05:30","relpermalink":"/post/new-parser/","section":"post","summary":"Chain of thoughts and intuition behind the idea","tags":["parsing","hmm"],"title":"Creating a New Synactic Parser?","type":"post"},{"authors":[],"categories":null,"content":"","date":1603801516,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801516,"objectID":"79c26ca2d8ff6f71edfb8dc4af24ecaa","permalink":"https://shreyagupta08.github.io/talk/neuro-ml/","publishdate":"2020-10-27T17:55:16+05:30","relpermalink":"/talk/neuro-ml/","section":"talk","summary":"","tags":[],"title":"Neuro Ml","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603801506,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801506,"objectID":"b483a7bdafa3119b8d1ca92b8c1331db","permalink":"https://shreyagupta08.github.io/talk/ama-tania-wu/","publishdate":"2020-10-27T17:55:06+05:30","relpermalink":"/talk/ama-tania-wu/","section":"talk","summary":"","tags":[],"title":"Ama Tania Wu","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603801481,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801481,"objectID":"5160d60488cc57ef4fb2a47074f42023","permalink":"https://shreyagupta08.github.io/talk/lcs2-xlnet/","publishdate":"2020-10-27T17:54:41+05:30","relpermalink":"/talk/lcs2-xlnet/","section":"talk","summary":"","tags":[],"title":"Lcs2 Xlnet","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603801474,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801474,"objectID":"730d56db97bc1f26591db9f34b2f9dc9","permalink":"https://shreyagupta08.github.io/talk/smiles/","publishdate":"2020-10-27T17:54:34+05:30","relpermalink":"/talk/smiles/","section":"talk","summary":"","tags":[],"title":"Smiles","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603801379,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801379,"objectID":"3e77653244f21fa99fa022bd7b9cd2c7","permalink":"https://shreyagupta08.github.io/talk/opportunity-rips/","publishdate":"2020-10-27T17:52:59+05:30","relpermalink":"/talk/opportunity-rips/","section":"talk","summary":"","tags":[],"title":"Opportunityrips","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603801367,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801367,"objectID":"748cf6ac2fe2704049ca40d96d4b9f50","permalink":"https://shreyagupta08.github.io/talk/opportunity-wtm/","publishdate":"2020-10-27T17:52:47+05:30","relpermalink":"/talk/opportunity-wtm/","section":"talk","summary":"","tags":[],"title":"Wtm","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603801304,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801304,"objectID":"f17c4d5759e8e8f68e828a6001e086fe","permalink":"https://shreyagupta08.github.io/talk/practicallyml/","publishdate":"2020-10-27T17:51:44+05:30","relpermalink":"/talk/practicallyml/","section":"talk","summary":"","tags":[],"title":"Practically ML","type":"talk"},{"authors":[],"categories":[],"content":"","date":1603801248,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603801248,"objectID":"0399b145bb08f71306e10488f73c389f","permalink":"https://shreyagupta08.github.io/publication/rips/","publishdate":"2020-10-27T17:50:48+05:30","relpermalink":"/publication/rips/","section":"publication","summary":"","tags":[],"title":"Rips","type":"publication"},{"authors":[],"categories":[],"content":"","date":1603799773,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603799773,"objectID":"4c35bcb5e7929d30869027f3e2a653f0","permalink":"https://shreyagupta08.github.io/publication/deep-learning-software-engg-slr/","publishdate":"2020-10-27T17:26:13+05:30","relpermalink":"/publication/deep-learning-software-engg-slr/","section":"publication","summary":"","tags":[],"title":"Deep Learning Software Engg Slr","type":"publication"},{"authors":[],"categories":[],"content":"","date":1603799729,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603799729,"objectID":"f0b43a0fc8271142740c502cdd840141","permalink":"https://shreyagupta08.github.io/publication/neural-correlates-iitd/","publishdate":"2020-10-27T17:25:29+05:30","relpermalink":"/publication/neural-correlates-iitd/","section":"publication","summary":"","tags":[],"title":"Neural Correlates Iitd","type":"publication"},{"authors":["Shreya Gupta"],"categories":[],"content":"Flair detector is a web application, deployed using Heroku. The application can be seen here. It scrapes posts using the URL and then uses a Random Forest model to predict the flair of the post.\nThe project contains the code which performs the following functionalities:\n Scrapping posts from Indian Subreddit according to two methods: hottest posts and distributed posts in accordance with flairs Exploratory Data Analysis: contains bar graphs and pie-charts to analyse data distributions for the attributes collected in step 1. Textual Pre-Processing: pre-processes textual data for attributes like Title of the post and Content of the posts. Building and contrasting different models: Builds, trains and validates four ML models, Naive Bayes, Random Forest, Logistic Regression and Multi-layer Perceptron using different features and then selects the feature-model pair performing the best. Building Web Application: Contains the code to build a basic web application that takes as input a post url and displays the predicted flair of the post. Hosts the app on Heroku.  My experimental log on how I designed the project along with the project code and documentation on how to run it in your local machine can be found here\nGood things about the project:  Detailed Documentation Prediction for Photography posts (generally)  Scopes of improvement:  Prediction. I realised it a little late that the 71% accuracy in using title as feature (and Random Forest as learning algorithm) is achieved because the title contained the flair in most cases. This was weird and has been mentioned in better detail in the Experimental log.ipynb file. Time remaining, I would have liked to find a way to:  incorporate comments, content and title with the title (and dealing with NaNs appropriately) Used better learning algorithms collected more data.    Future work: In data exploration:\n  finding the number of posts in each flair for which content != None\n finding the correlation between individual flair confusion matrix obtained from using content only with the number of samples obtained above verifying if the unequal distribution is one of the reasons behind the low flair accuracy. if yes, checking if increasing the number of sample distribution had any effect on prediction scores. Then maybe, content would not have been as useless after all.    contrasting performance with unsupervised algorithms (like K-Means)\n  Find flair-wise accuracy\n  ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"4d3a5e34dce80c9aa6a5d5b6de3af95d","permalink":"https://shreyagupta08.github.io/project/flare-detector/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/flare-detector/","section":"project","summary":"Project done as a task for MIDAS Lab to design end-to-end pipeline to predict submission flares for Indian subreddit. Extracts data, analyses it, builds a model, develops a web application and deploys it in Heroku","tags":["machine learning","flare detection","reddit"],"title":"Flare Detector for Reddit Data","type":"project"},{"authors":["Shreya Gupta"],"categories":[],"content":"In the summers of 2019, I had the opportunity to work with a team of three talented researchers, with support of an academic advisor (Dr. Bao Wang) and with two industrial advisors (Vardhan Akopian and Scott Schneider), under the RIPS scholarship program conducted by Institute of Pure and Applied Mathematics, UCLA.\nIntroduction: RIPS Internship RIPS stands for Research in Industrial Projects for Students. It is an annual research program organised by the Institute of Pure and Applied Mathematics (IPAM) of UCLA. With an acceptance rate of 3%, it hosts every year 36 interns who work on 9 industrial projects in groups of 4. I was one of the interns selected for the year 2019. Application Procedure and pre-intern experience is available here and Personal Experience is covered here.\nTHE INTERNSHIP RIPS is a crossover between research and industrial experience. We are given an industrial problem and have to solve it using quantitative and qualitative research. Each year witnesses industrial companies bringing their problems. I had a chance to work, with my fellow teammates, for Google, LA.\nProblem Description Google has an Ads Data Hub (ADH) for advertisers (customers) to analyze their ad campaigns (system diagram in figure 1). The advertisers can not see the raw data, for it can violate users' privacy. Hence advertisers can query the database to generate useful analytics. ADH has its own privacy filters so that advertisers only obtain aggregate results. Despite those filters, leaks can still occur. Our goal was to develop a framework that can measure the risk of privacy leaks in Google\u0026rsquo;s ADH.\n  Figure 1: High level overview of working of ADH  Conclusion We provided Google, LA with the necessary deliverables, designing a framework that gives a risk assessment score descriptive of how at risk each user is and how each attribute contributes to the risk. We call it the PIRATE Score (Probabilistic Identification Risk and Attacker Threat Estimate score). Paper for the same will soon be available.\nTangibles We presented our work to RIPS Colloquium. Our research was selected to represent RIPS at the annual CUR Sympoisum, held at Alexandria, Virginia, where we were selected to present a poster. The work received recognition and appreciation for its logical improvisation and technical extention of the previous state-of-the-art methodology [1]. Additionally, the work received Outstanding Poster Award at Joint Mathematics Meet 2020, held at Denver and Best Poster Award at ACSS held at IIIT-Delhi. The project\u0026rsquo;s report is available on request.\nSlides, Presentation recording and project report available on request Feel free to email at shreyag [at] iiitd [dot] ac [dot] in - if you are interested in discussing the work, perusing the report or both.\nReferences:\n[1] Streit, M., Dammers, J., Simsek-Kraues, S., Brinkmeyer, J., Wolwer, W., Ioannides, A.: Time course of regional brain activations during facial emotion recognition in humans. Neurosci. Lett. 342(12), 101–104 (2003)\n","date":1568937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568937600,"objectID":"1516141c9662229be3c299e1283234b6","permalink":"https://shreyagupta08.github.io/project/rips/","publishdate":"2019-09-20T00:00:00Z","relpermalink":"/project/rips/","section":"project","summary":"My work done as a part of RIPS internship - in Institute of Pure and Applied Mathematics, UCLA and with Google, LA - on measuring privacy leaks to protect the end-user safety while making online search databases useful for advertisers","tags":["privacy protection","IPAM","UCLA","Google"],"title":"Risk Assessment and Measurement of Privacy Leak in Google's Ads Data Hub","type":"project"},{"authors":["Shreya Gupta"],"categories":[],"content":"Motivation and Journey (before application) I applied for WTM scholarship for the first time on 8th August 2018. It was during the application process I realised that I hadn’t done anything significant for the underrepresented community that I had always been so vocal about. Immediately after submitting the application I dropped a text to my college senior who I came to know was extensively involved in uplifting women-in-tech. I met her, and started volunteering in events held by Women Who Code Delhi and Women in Machine Learning and Data Science (WiMLDS) Delhi. Eventually I joined them, organised and delivered a talk, mentored a group of 7 students, and conducted a 4-part lecture series on Machine Learning from an implementation and practical point of view. In the year of 2019, I applied again.\nApplication Process In addition to resume, the application asked us for answers to three essay questions that asked us:\n How we became interested in Computer Science and what our goals were in the field. Activities we were involved to address challenges faced by the underrepresented groups in CS. Technical report on a project we did.  This time around I was more confident writing answers to these questions. Additionally I got my answers reviewed by a past scholar and a very dear friend.\n Suggestion for Essay Answers:\n  Know your ‘why’ of applying. Give concrete reasons, citing personal examples and try to stay away from cliche phrases. Understand your journey and be genuine with what you write. Use links as a proof of your words.  Pre-Retreat Experience and Selection Process I was in Los Angeles, on 27 June 2019, when I received an email from them telling me I had made it through the first round. The next and final round consisted of a telephonic interview with a Googler in a couple of days. Scheduling the call was an eventful task because of the time difference but when the interview finally happened, it was a great 30 minute conversation. It was a casual one-on-one conversation. The conversation started with a ‘Tell-me-about-yourself’ and by the end we were discussing:\n How important organisations and communities are if we are to remove gender disparity How to empower women to fight for equal rights in and outside workplaces and how we could not please everybody.  The Googler asked me:\n The community work I was involved in how I would keep a women-in-tech organisation afloat how I encourage more women to participate and volunteer in the events how I respond to guys who condemn these organisations that promote gender equality in STEM fields. about my research project at IIT-Delhi and grasped the specifics very quickly  She asked me how and why Women Techmakers was important for me. I told her it would give me an opportunity to connect with fellow scholars who have been doing exceptional work in this domain; would help me to take my regional organisations on a global scale, improving its outreach and learning from the fellow scholars. (After the retreat, I organised our first cross-country webinar with a scholar from Taiwan, something that has never happened in WTM APAC history, as told to me by my country Point Of Contact.) On 11 June 2019 I received an email titled ‘Congratulations! Women Techmakers Scholars Program 2019’. It was 2.11 am Pacific Time and sitting next to a fellow intern from Pakistan, I remember looking at him with bright eyes and simply turning my laptop screen towards him.\n Suggestions related to the interview:\n  Go through your resume, essay answers and other application material carefully before the interview. Prepare answers for the customary questions before (this gives you confidence during your interview if you tend to get nervous for things you’ve been waiting for, like me). The generic questions include:   “Describe yourself” Your technical skills Every activity/initiative you are undertaking/have done for the underrepresented community in tech Why you? Why wtm? What would you do at and after the retreat? Do you have any questions for me?  Most importantly, talk about your journey. Give personal examples, be genuine and honest.  Finally, don’t undersell yourself. Don’t be boastful either. State things you did, without thinking something is too small or too big! Be confident! You got this!\n Detail about the retreat is available on my medium blog\n FINAL WORDS The three days were absolutely amazing. I got to interact with some AMAZING Googlers and scholars, ask them questions about their work and talk about my work. It was not only fostering to know it is okay to not know but also to learn to talk about your achievements with pride instead of hiding them or feeling like an imposter. It has been more than a month since the retreat (at the time of writing this blog) and every time I see a post from a fellow scholar, it brings about a smile on my face of all the things they are doing! I am so proud of my girls. I have reached out to my fellow scholars for collaborations and so have they. After a long time it feels so great to be surrounded by people who talk about tech and life and deeply want to bring a change in the position of women and other minorities in the tech field.\n 2020’s WTM Applications are open. The link for the same is: http://services.google.cn/fb/forms/womentechmakersscholarsprogram2020-apac/\n If you are eligible, I will definitely suggest you to apply! Feel free to reach out to me at shreyagupta0806 [at] gmail [dot] com for any help.\nSlides on WTM from an event I presented here All the best! Thank you Google!\nNote: Images clicked by Google WTM OC subject to copyright. ","date":1567341557,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567341557,"objectID":"728d0e69a06f255d995f7625faa364fd","permalink":"https://shreyagupta08.github.io/post/wtm/","publishdate":"2019-09-01T18:09:17+05:30","relpermalink":"/post/wtm/","section":"post","summary":"My brief journey before applying for WTM, the application process (and takeaways) and an insight into what goes in the WTM retreat","tags":["WTM","Google"],"title":"Google Women Techmakers Experience 2019","type":"post"},{"authors":["Shreya Gupta"],"categories":null,"content":"Introduction: RIPS Internship RIPS stands for Research in Industrial Projects for Students. It is an annual research program organised by the Institute of Pure and Applied Mathematics (IPAM) of UCLA. With an acceptance rate of 2-3%, it hosts every year 36 interns who work on 9 industrial projects in groups of 4. I was one of the interns selected for the year 2019 and this post describes my application process and experience. The intern and personal experience will be covered in a separate post.\nAPPLICATION AND PRE-SELECTION EXPERIENCE: By the end of September I had secured two on-campus internships at Morgan Stanley and Adobe but something inside me was not satisfied. So I started applying for research internships abroad. It is especially tough in our culture because we don’t have any curated list so refer to this link which contains a non-exhaustive list of internships (some exclusively for Indian students). I was selective when applying for internships because I knew they are highly competitive and anyone having an aggregate CGPA of \u0026lt;9.5 (out of 10) has less chance securing some of them.\nFast forward to February, I was getting frustrated with not getting any results. I remember sitting in the library of IIT-D, waiting for my professor to return from his meeting to wrap up my paper with him. I had a couple of hours and decided to apply for one final intern. It was Research in Industrial Projects for Students, or RIPS, offered by Institute of Pure and Applied Mathematics (IPAM), residing in UCLA. I was interested in applying for it partly because mathematics and CS always appealed to me, and somewhat because I was torn between academia and industry and this internship seemed to be the perfect mix of both. I was also interested because my college senior (who I look up to) secured this internship the previous year and I remember him telling me how great his experience was (great would be an understatement). So there I was, sitting in the library, with my friend from FIITJEE days by my side, stressed and freakishly writing answers for which math and CS courses I had taken, which languages I had worked on (and by what scale) and describing the major projects I had worked on. I wasn’t required to write a Statement of Purpose but was asked to upload my college transcripts and 2 Letter of Recommendations (LORs) from my professors. I sat there for the entire day and filled the form up. I requested my professors to upload a LOR telling IPAM people how I am the best, most passionate and funny person everr! They were happy to (Big shoutout to Dr. Ruchika Malhotra, my guide).\nFast forward to February 28, I had come back from my bitter-sweet conference and had to leave for Kerala to participate in Smart India Hackathon with my awesome team. I woke up at 6 am, and as usual checked my email the first thing in the morning. But unlike most mornings where I only got mails from Grammarly, KDNuggets and Medium, this time I had an email that was titled ‘UCLA RIPS-Summer REU’ from a Dimi. It said they were interested in offering me an intern position at their esteemed RIPS program. I refused to believe. Few hours later, I was in metro with my luggage to board my flight when I opened my laptop and showed my friend the email. He made me believe I was crazy, and I finally accepted what had just happened and replied back.\nFinally in second week of March (a night before my Operating Systems mid-term examination), just before I was going to bed, at 12.15 am, I received an email that said ‘RIPS LA 2019 Offer Letter’ and I remember going to my friends in adjacent room and showing them the email. The next few minutes were about shedding some tears and staying in disbelief. I told my two awesomesauce seniors, mentors and guides, and as always they made me realise how big it was and congratulated me in the best way possible! (In words of one of them: Right now, I am this person who is sitting in a Google meeting room smiling like crazies).\nKey take-aways:\n Refer to this link and contribute to it if you find other internships. Don’t apply everywhere. Be selective and invest your effort and time only in programs that align with your ideology. Don’t stop yourself from applying just because you don’t think you have a shot (Imposter Syndrome). You have a shot. But only if you put yourself out there. Apply. Have a good support system, progressive friends and consistent mindset. If I can do it, so can you. You got this. Go and apply.  This is the link to RIPS official page. The applicaions generally open in November and the deadline is usually February second week.\nHope this was helpful. If you have any other queries regarding the application process, contact me on my email id: shreyag [at] iiitd [dot] ac [dot] in\n The amazing team  -- All the best!\n","date":1566950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566950400,"objectID":"4132f8af567c82d41228cdbaf821d90c","permalink":"https://shreyagupta08.github.io/post/rips-experience/","publishdate":"2019-08-28T00:00:00Z","relpermalink":"/post/rips-experience/","section":"post","summary":"Application and Pre-intern experience as a RIPS Scholar under IPAM, UCLA and Google, LA for the summers of 2019.","tags":["Research intern","Application","IPAM","UCLA"],"title":"RIPS at IPAM, UCLA - Application and Pre-Intern Experience 2019","type":"post"},{"authors":["Shreya Gupta"],"categories":null,"content":"For the past few years every time I travelled to a hill station: to rivers in the north east, in the gravel grounds and through the sea green Psangong lake of Leh, the green in Kashmir, I’ve wondered what we are trading in our big urban clogged up cities. I’ve dreamt living a life in a town dreams are made of.\nIt was only until the recent trip to my maternal grandparents house that I realised what the temptation was all about. When I saw my mother unite with her two sisters, one elder another younger, at the midnight between the elder’s birthday the past day and my mother’s that day, all present by the absolute token of coincidence and some persistence with their husbands, cake smudged on their faces, some deservedly, others forcefully and for the symmetry, I caught, as I clicked pictures, the deep rooted reason. Between working their lives to make their parents proud and never let their children see what they had to, and watching their lives take disparate tangents along the process, they were stealing a moment. Stealing a moment between past’s unsynchronisation and future’s uncertainty.\nTravelling in the bus, squeezed, watching a documentary on Netflix, as the internet goes down, I look up and right, outside the nearest window, to gauge the green paddy fields and a light drizzle. Instantaneously amongst serious facial lines, a smile appeared, almost reflexivily and involuntarily. I realised this was a moment I stole.\n It is for these little moments that we steal in our everyday lives, every once in a while, that makes us complete.\n Watching an episode of Friends when you have deadlines to meet; sneaking out of your home, picking your best friend along the way and going to your favourite stall on the street when you have an important test coming up; a casual walk in the park; stopping to look at a baby with bubbly eyes for 5 minutes straight; helping an acquaintance out; laughing on something stupid; a 3 hour ‘power nap’; these are the little moments that make life life.\nWhen was the last time you stole a moment? ","date":1560643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560643200,"objectID":"d2888eec43f9b0170d0d244111419be5","permalink":"https://shreyagupta08.github.io/post/travelling-respite/","publishdate":"2019-06-16T00:00:00Z","relpermalink":"/post/travelling-respite/","section":"post","summary":"Thoughts while travelling","tags":["travel"],"title":"Travelling Respite","type":"post"},{"authors":["Shreya Gupta"],"categories":[],"content":"In the summers of 2018, I had the opportunity to work under Dr. Tapan Gandhi, IIT Delhi, in his Neuroscience Lab, on using machine learning to design an Artificial Face Recognition model that worked similar to how a human brain recognises faces.\nProblem Existing face detection algorithms rely on massive amounts of data and perform poorly with angle and light variations [1]. Human brain, on the contrary, faces none of the above problems. Thence, using computational neuroscience to process MEG recordings of users, and support-vector machines for classification in MATLAB, I found responsive sensors and concentrated timestamps during which identification occurred.\nFindings We found that human brain identifies a face between the first 120-240 ms of seeing it. Additionally, the most responsive sensors are located near occipitotemporal and occipitoparietal lobes and few in frontal lobe. Thus, by identifying the active sensors and the differentiating time stamps, the work was able to filter out noisy and less effective sensors and time slots. This mitigates the computational costs of the model built for face recognition by providing researchers the channels and slots to focus their research on.\nThe groundwork trims the active timestamp range by more than half of the existing state-of-the-art algorithm [2]. I presented this work at the ​IEEE International Symposium ISCMM 2019 (figure 1) ​and published it in the Scopus indexed ​Advances in Intelligent Systems and Computing ​(AISC) [3].\nFuture Work Using eye-tracking, the findings of this paper can be extended to extract features captured by the eyes during the mentioned time stamps (124–240 ms) which enabled brain to detect and classify faces.\n From this project, I learned the importance of pragmatic pre-processing and coding efficient solutions for real-life high-dimensional data.\n   -- Conference Presentation Link: https://bit.ly/2r6kw9n\nReferences:\n[1] Khurana, P., Sharma, A., Singh, SN., Singh, P.K.: A survey on object recognition and segmentation techniques. In: 3rd International Conference on Computing for Sustainable Global Development (INDIACom), pp. 3822–3826 (2016)\n[2] Streit, M., Dammers, J., Simsek-Kraues, S., Brinkmeyer, J., Wolwer, W., Ioannides, A.: Time course of regional brain activations during facial emotion recognition in humans. Neurosci. Lett. 342(12), 101–104 (2003)\n[3] Gupta, S., Gandhi, T.: Identification of Neural Correlates of Face Recognition Using Machine Learning Approach. Advances in Intelligent Systems and Computing, vol 992. Springer, Singapore (2020)\n","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"76064ec2b913578a0a53bfc2e69cce91","permalink":"https://shreyagupta08.github.io/project/iitd/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/project/iitd/","section":"project","summary":"My research experience under Dr. Tapan Gandhi, Indian Institute of Technology (IIT), Delhi, on using computational neuroscience and machine learning to design an artificial face recognition model for patients with Autism and Prosopagnosia","tags":["machine learning","neuroscience","face recognition"],"title":"Identification of Neural Correlates of Face Recognition Using Machine Learning Approach","type":"project"},{"authors":["Shreya Gupta"],"categories":[],"content":"In the SIH edition of 2019, I along with my five other teammates got an opportunity to be one of the top four teams selected from across India for Thermofischer\u0026rsquo;s problem statement in Asia\u0026rsquo;s biggest Hackathon, the Smart India Hackathon.\nUnder this project, we proposed a real-time epidemic mapping system which can work on the basis of trustworthy crowdsourced data to not only analyze the current epidemic but also prevent the future ones by providing intelligent estimates using state of the art machine learning and artificial intelligence techniques.\n  Flowchart of our proposed model  Epidemiology is the study and analysis of the distribution and determinants of health and disease conditions in defined populations. With help of modern communication technologies, this can be done more effectively and faster than ever to yield extraordinary results in\n Analyzing Containing Predicting Generating Real-time warnings and awareness on epidemic outbreaks.  Our proposed model and its source code are available here\n Our Super Cool Team '2b||!2b' after 3 hours of sleep in 2 days!  -- ","date":1551571200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551571200,"objectID":"fc86a146397a5ad8b0bebe31234198d8","permalink":"https://shreyagupta08.github.io/project/epidemic-spread/","publishdate":"2019-03-03T00:00:00Z","relpermalink":"/project/epidemic-spread/","section":"project","summary":"Project done as a part of Smart India Hackathon 2019, to design an epidemic identification, mapping and prediction system for Thermofischer and connect people to nearby hospital and drug stores in case of an epidemic.","tags":["machine learning","deep learning","epidemic spread","prediction"],"title":"Epidemic Spread Tracking and Prediction","type":"project"},{"authors":[],"categories":[],"content":"In January 2019, I had the opportunity to be in the top 20 teams to be selected for a two day hackathon - Wintathon by LinkedIn. The hackathon was hosted at their Bangalore office. For the hackathon, we decided to design a voice assistant for LinkedIn.\nThe code, presentation and demo for the project is available here\nLearnings  This project taught me how to implement statistical NLP metrics integrate the code while designing an application that is functional be realistic while presenting a work in terms of not only the social impact but also on how well a model does what it is supposed to do.  ","date":1548028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548028800,"objectID":"477bf2626e5a08fdb2ebcb3e75db488a","permalink":"https://shreyagupta08.github.io/project/voice-assistant/","publishdate":"2019-01-21T00:00:00Z","relpermalink":"/project/voice-assistant/","section":"project","summary":"Project done as a part of LinkedIn Wintathon 2019. The voice assistant can search for people, jobs, navigate and apply, and add profile sections with interactive form based UI.","tags":["machine learning","voice assistant","LinkedIn","Wintathon"],"title":"Voice Assistant for LinkedIn","type":"project"},{"authors":["Shreya Gupta"],"categories":[],"content":"This was about Winter break of my third year (Dec, 2018) and I wanted to venture out in the field of Natural Language Processing. I took this project up from a basic Kaggle competition and used the sample solution in the following steps:\n I imported the code into my local machine I didn\u0026rsquo;t run it but understood each line in a top to bottom fashion. From text pre-processing to the concept of word vectors, bag of words and finally word2vec. I didn\u0026rsquo;t just use that one list of code but also read blogs and watched videos on how these basic linguistics were implemented and conceptualised. Finally, I wrote each line of code myself, ran it, de-bugged it, played with it and pushed it.  Learnings:  This project was aimed at understanding the foundations of NLP: tokens, pre-processing segments and the concept of vectors I learned two different approaches to vectorise words and sentences : bag of words and word2vec  These may seem insignificant in the longer run for the trivial concepts they are, but at the time of this project I was proud that instead of spending months on a course with no practical understanding of the fundamentals and implementation of a methodology, I instead learned the concepts in a practical way in just 14 days.\nProject code is available here\n","date":1545350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545350400,"objectID":"7da182e0050c13c9e624475feb2b697e","permalink":"https://shreyagupta08.github.io/project/movie-review-classifier/","publishdate":"2018-12-21T00:00:00Z","relpermalink":"/project/movie-review-classifier/","section":"project","summary":"Self undertaken project that classifies movie reviews from IMDb using Google's Word2Vec","tags":["machine learning","natural language processing","movie review","classification"],"title":"IMDb Movie Review Classifier using Word2Vec","type":"project"}]